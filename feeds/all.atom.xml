<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ahmad Al-Shishtawy</title><link href="https://alshishtawy.github.io/" rel="alternate"></link><link href="https://alshishtawy.github.io/feeds/all.atom.xml" rel="self"></link><id>https://alshishtawy.github.io/</id><updated>2021-09-16T00:00:00+02:00</updated><subtitle>Senior Researcher, PhD</subtitle><subtitle>Senior Researcher, PhD</subtitle><entry><title>The Ultimate Guide to Using an External Python Kafka Client to Interact with a HopsworksÂ Cluster</title><link href="https://alshishtawy.github.io/kafka-hopsworks.html" rel="alternate"></link><published>2021-09-16T00:00:00+02:00</published><updated>2021-09-16T00:00:00+02:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2021-09-16:/kafka-hopsworks.html</id><summary type="html">&lt;p class="first last"&gt;We illustrate how to configure and use the python Confluent Kafka client to interact externally with a Hopsworks cluster. This include how to publish (write) and subscribe to (read) streams of events and how to interact with the schema registry and use Avro for data&amp;nbsp;serialization.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In this guide, we illustrate how to configure and use the python Confluent Kafka client to interact externally with a Hopsworks cluster. This include how to publish (write) and subscribe to (read) streams of events and how to interact with the schema registry and use Avro for data&amp;nbsp;serialization.&lt;/p&gt;
&lt;p&gt;This tutorial was tested using Hopsworks version&amp;nbsp;2.2.&lt;/p&gt;
&lt;div class="section" id="prepare-the-environment"&gt;
&lt;h2&gt;Prepare the&amp;nbsp;Environment&lt;/h2&gt;
&lt;p&gt;We&amp;#8217;ll start by preparing the schema, creating a Kafka topic, and downloading security credentials that we&amp;#8217;ll need in this&amp;nbsp;tutorial.&lt;/p&gt;
&lt;div class="section" id="avro-schema"&gt;
&lt;h3&gt;Avro&amp;nbsp;Schema&lt;/h3&gt;
&lt;p&gt;Kafka treats data as blobs of bytes. It is your responsibility to pick a data format per topic and use it consistently across applications interacting with the topic. You are free to choose any format you prefer such as &lt;span class="caps"&gt;JSON&lt;/span&gt; or Protobuf. However, &lt;a class="reference external" href="http://avro.apache.org/docs/current/"&gt;Avro&lt;/a&gt; became the industry standard for data format to use with Kafka. Avro is an open source data serialization system that is used to exchange data between systems across programming&amp;nbsp;languages.&lt;/p&gt;
&lt;p&gt;Avro relies on schemas that are used when writing/reading data. To simplify the management of schemas, Confluent implemented a
&lt;a class="reference external" href="https://docs.confluent.io/platform/current/schema-registry/index.html"&gt;Schema Registry&lt;/a&gt; as a layer on top of Kafka. Hopsworks implements its own schema registry that is compatible with Confluent Schema Registry v5.3.1. Kafka clients can use the schema registry to validate and make sure that the correct data is written to or read from a kafka&amp;nbsp;topic.&lt;/p&gt;
&lt;p&gt;In this tutorial, we&amp;#8217;ll use temperature sensors as an example. Each sensor will have a unique &lt;strong&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/strong&gt;, produce a temperature as its &lt;strong&gt;value&lt;/strong&gt; at a specific &lt;strong&gt;timestamp&lt;/strong&gt;. We&amp;#8217;ll create a generic sensor schema that can be used with sensors with similar pattern.
The code blow list the schema used in this tutorial.
For more details about declaring Avro schemas and supported data types, check the &lt;a class="reference external" href="https://avro.apache.org/docs/current/spec.html#schemas"&gt;Avro schemas&lt;/a&gt;&amp;nbsp;documentation.&lt;/p&gt;
&lt;!-- hops `schema_management`_ --&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;record&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sensor&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;fields&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;timestamp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;long&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;logicalType&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;timestamp-millis&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;string&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;double&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To register the above schema in Hopsworks, open the schemas settings in the Kafka tab and select &lt;strong&gt;New Avro&amp;nbsp;Schema&lt;/strong&gt;&lt;/p&gt;
&lt;img alt="Avro schema settings page" class="align-center" src="https://alshishtawy.github.io/images/kafka/avro_schema.png" style="width: 100%;" /&gt;
&lt;p&gt;Then enter a &lt;strong&gt;Schema Name&lt;/strong&gt; field for your schema and paste the schema itself in the &lt;strong&gt;content&lt;/strong&gt; field.
To check that the syntax of the schema is correct, press the &lt;strong&gt;Validate&lt;/strong&gt; button. If everything is &lt;span class="caps"&gt;OK&lt;/span&gt; proceed by pressing the &lt;strong&gt;Create&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;
&lt;div class="admonition caution"&gt;
&lt;p class="first admonition-title"&gt;Caution!&lt;/p&gt;
&lt;p class="last"&gt;For the schema to work correctly with standard external clients, such as the Confluent Avro Producer/Consumer, the name given in the &amp;#8220;Schema Name&amp;#8221; field and in the schema declaration &lt;strong&gt;must be the same name&lt;/strong&gt;.
Furthermore, if you use a name space in the schema declaration, e.g., &lt;tt class="docutils literal"&gt;&amp;quot;namespace&amp;quot;: &amp;quot;se.ri.kafka.tutorial&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;sensor&amp;quot;&lt;/tt&gt;, then the &amp;#8220;Schema Name&amp;#8221; field should contain the full name, i.e., &lt;tt class="docutils literal"&gt;se.ri.kafka.tutorial.sensor&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;img alt="Registring a new Avro schema" class="align-center" src="https://alshishtawy.github.io/images/kafka/avro_schema_new.png" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="kafka-topic"&gt;
&lt;h3&gt;Kafka&amp;nbsp;Topic&lt;/h3&gt;
&lt;p&gt;Topics are a way to organize related events. A topic is like a buffer between event producers and event consumers. Events are durably stored in a topic and are not deleted after consumption. Events can be read as many times as needed and you define for how long Kafka should retain your&amp;nbsp;events.&lt;/p&gt;
&lt;p&gt;For scalability, a topic is divided into a number of partitions that are distributed across servers (called Kafka Brokers). Events are distributed among partitions either uniformly or by event key. Using an event key is recommended to guarantee that events from the same entity, e.g., user or sensor, end up in the same partition and thus processed in the correct order of&amp;nbsp;arrival.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="first admonition-title"&gt;Tip&lt;/p&gt;
&lt;p class="last"&gt;The number of partitions determine the maximum parallelism for processing (consuming) events by a single application. You can have as many event producers per topic as you want. Also there can be as many applications processing (consuming) events from a topic as needed. But within a single application, also known as a &lt;strong&gt;consumer group&lt;/strong&gt;, the maximum parallelism (number of consumers) is defined by the number of partitions in the topic. This restriction is to guarantee the ordered processing of events within a&amp;nbsp;topic.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To create a new Kafka topic, open the topic settings in the Kafka tab and select &lt;em&gt;New Topic&lt;/em&gt;.&lt;/p&gt;
&lt;img alt="Kafka topics settings page" class="align-center" src="https://alshishtawy.github.io/images/kafka/kafka_topic.png" style="width: 100%;" /&gt;
&lt;p&gt;Give your topic a name. This will be used later in the code to identify the topic. Enter the desired number of partitions and replication degree. Select a schema and schema version to use with this topic. For this tutorial, use the values shown in the image&amp;nbsp;below.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;For testing, it is &lt;span class="caps"&gt;OK&lt;/span&gt; to set the number of partitions and replicas to 1. In a production system, you should always set the number of replicas to larger that 1 (typically 3) to avoid data loss on server failures and also select appropriate number of partitions to achieve the desired performance based on the expected number and rate of&amp;nbsp;events.&lt;/p&gt;
&lt;/div&gt;
&lt;img alt="Creating a new Kafka topic" class="align-center" src="https://alshishtawy.github.io/images/kafka/kafka_topic_new.png" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="security-certificates"&gt;
&lt;h3&gt;Security&amp;nbsp;Certificates&lt;/h3&gt;
&lt;p&gt;Hopsworks provide a secure Kafka-as-a-Service. Connecting your Python Producers and Consumers from an external server to the one provided by Hopsworks requires exporting the project certificates. These are used by the clients to securely connect and authenticate against the Hopsworks Kafka cluster. The certificates are downloaded as a keystore and trustore. These are designed used by Java/Scala programs and needs to be converted to &lt;em&gt;.pem&lt;/em&gt; format to be used by Python and other non Java&amp;nbsp;programs.&lt;/p&gt;
&lt;p&gt;To export your projects&amp;#8217; certificates, go to &lt;em&gt;Project Settings&lt;/em&gt; in the &lt;em&gt;Settings&lt;/em&gt; tab and click &lt;em&gt;Export Certificates&lt;/em&gt;.&lt;/p&gt;
&lt;img alt="Project settings page" class="align-center" src="https://alshishtawy.github.io/images/kafka/project_settings.png" style="width: 100%;" /&gt;
&lt;p&gt;You will be asked to enter your login password before&amp;nbsp;downloading.&lt;/p&gt;
&lt;img alt="Exporting project certificates (1/2)" class="align-center" src="https://alshishtawy.github.io/images/kafka/project_settings_export_1.png" style="width: 100%;" /&gt;
&lt;p&gt;After successfully entering your password, two certificate files will be downloaded, trustStore.jks and keyStore.jks. The certificate password will be displayed. It&amp;#8217;s a long string that is similar&amp;nbsp;to:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;&lt;span class="caps"&gt;MQJNW833YNBR9C0OZYGBGAB09P2PP4H5EHIALGWIT98I2PNSPTIXFCEI72FT0VLE&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="first admonition-title"&gt;Important&lt;/p&gt;
&lt;p class="last"&gt;Store these two files in a safe place as they give remote access to your project and data. Same goes for the password. Copy and save your password in a safe location as we&amp;#8217;ll need it&amp;nbsp;later.&lt;/p&gt;
&lt;/div&gt;
&lt;img alt="Exporting project certificates (2/2)" class="align-center" src="https://alshishtawy.github.io/images/kafka/project_settings_export_2.png" style="width: 100%;" /&gt;
&lt;p&gt;Next, we&amp;#8217;ll convert the &lt;span class="caps"&gt;JKS&lt;/span&gt; keyStore into an intermediate &lt;span class="caps"&gt;PKCS&lt;/span&gt;#12 keyStore, then into &lt;span class="caps"&gt;PEM&lt;/span&gt; file.
You will be asked to enter a new password for each of the generated certificates and also the original certificate password you got from the previous&amp;nbsp;step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ keytool -importkeystore -srckeystore keyStore.jks &lt;span class="se"&gt;\&lt;/span&gt;
   -destkeystore keyStore.p12 &lt;span class="se"&gt;\&lt;/span&gt;
   -srcstoretype jks &lt;span class="se"&gt;\&lt;/span&gt;
   -deststoretype pkcs12
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ keytool -importkeystore -srckeystore keyStore.jks -destkeystore keyStore.p12 -srcstoretype jks -deststoretype pkcs12
Importing keystore keyStore.jks to keyStore.p12...
Enter destination keystore password:
Re-enter new password:
Enter source keystore password:
Entry for alias kafka_tutorial__meb10000 successfully imported.
Import command completed:  1 entries successfully imported, 0 entries failed or cancelled
&lt;/pre&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl pkcs12 -in keyStore.p12 -out keyStore.pem
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ openssl pkcs12 -in keyStore.p12 -out keyStore.pem
Enter Import Password:
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
$ ls
keyStore.jks  keyStore.p12  keyStore.pem  trustStore.jks
&lt;/pre&gt;
&lt;p&gt;We repeat the same steps for the&amp;nbsp;trustStore.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ keytool -importkeystore -srckeystore trustStore.jks &lt;span class="se"&gt;\&lt;/span&gt;
   -destkeystore trustStore.p12 &lt;span class="se"&gt;\&lt;/span&gt;
   -srcstoretype jks &lt;span class="se"&gt;\&lt;/span&gt;
   -deststoretype pkcs12
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ keytool -importkeystore -srckeystore trustStore.jks -destkeystore trustStore.p12 -srcstoretype jks -deststoretype pkcs12
Importing keystore trustStore.jks to trustStore.p12...
Enter destination keystore password:
Re-enter new password:
Enter source keystore password:
Entry for alias hops_root_ca successfully imported.
Import command completed:  1 entries successfully imported, 0 entries failed or cancelled
&lt;/pre&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl pkcs12 -in trustStore.p12 -out trustStore.pem
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ openssl pkcs12 -in trustStore.p12 -out trustStore.pem
Enter Import Password:
$ ls
keyStore.jks  keyStore.p12  keyStore.pem  trustStore.jks  trustStore.p12  trustStore.pem
&lt;/pre&gt;
&lt;p&gt;Now you should have &lt;tt class="docutils literal"&gt;keyStore.pem&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;trustStore.pem&lt;/tt&gt; that we&amp;#8217;ll use in the rest of this tutorial. You can safely delete the intermediate &lt;tt class="docutils literal"&gt;.p12&lt;/tt&gt; files.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="api-key"&gt;
&lt;h3&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&amp;nbsp;Key&lt;/h3&gt;
&lt;p&gt;Hopsworks provides a rich &lt;a class="reference external" href="https://app.swaggerhub.com/apis-docs/logicalclocks/hopsworks-api"&gt;&lt;span class="caps"&gt;REST&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; to interact with most of the available services. One of these services is the &lt;em&gt;Schema Registry&lt;/em&gt; that we&amp;#8217;ll be using in this tutorial. To access the &lt;em&gt;&lt;span class="caps"&gt;REST&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/em&gt; we&amp;#8217;ll need an &lt;em&gt;&lt;span class="caps"&gt;API&lt;/span&gt; Key&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To create a new &lt;span class="caps"&gt;API&lt;/span&gt; Key associated with your account, open your user account&amp;nbsp;settings.&lt;/p&gt;
&lt;img alt="Account Settings" class="align-center" src="https://alshishtawy.github.io/images/kafka/account_settings.png" style="width: 100%;" /&gt;
&lt;p&gt;Select the &lt;span class="caps"&gt;API&lt;/span&gt; Keys tab. Give your key a name and select the services that the app using this key can access. Then click on &lt;em&gt;Create &lt;span class="caps"&gt;API&lt;/span&gt; Key&lt;/em&gt;.&lt;/p&gt;
&lt;img alt="Account Settings - API Keys tab" class="align-center" src="https://alshishtawy.github.io/images/kafka/account_settings_api_key_1.png" style="width: 100%;" /&gt;
&lt;p&gt;Copy and store your new key in a safe plase as this is the only time it will be displayed. If you loose your &lt;span class="caps"&gt;API&lt;/span&gt; Key you&amp;#8217;ll have to delete it and create a new&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;Your &lt;span class="caps"&gt;API&lt;/span&gt; Key will look somethin like&amp;nbsp;this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;tt class="docutils literal"&gt;K97n09yskcBuuFyO.scfQegUMhXfHg7v3Tpk8t6HIPUlmIP463BPdbTSdSEKAfo5AB8SIwY8LGgB4924B&lt;/tt&gt;&lt;/blockquote&gt;
&lt;div class="admonition important"&gt;
&lt;p class="first admonition-title"&gt;Important&lt;/p&gt;
&lt;p class="last"&gt;Store your &lt;span class="caps"&gt;API&lt;/span&gt; Key in a text file (e.g., apiKeyFile) next to your certificates. We&amp;#8217;ll use this file later to configure&amp;nbsp;clients.&lt;/p&gt;
&lt;/div&gt;
&lt;img alt="Creating an API Key" class="align-center" src="https://alshishtawy.github.io/images/kafka/account_settings_api_key_2.png" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="project-name-and-id"&gt;
&lt;h3&gt;Project Name and &lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The final piece if information we need is the project name and &lt;span class="caps"&gt;ID&lt;/span&gt;. You will find this in your project settings&amp;nbsp;tab.&lt;/p&gt;
&lt;img alt="Project Name and ID" class="align-center" src="https://alshishtawy.github.io/images/kafka/project_settings_name_id.png" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="avro-client"&gt;
&lt;h2&gt;Avro&amp;nbsp;Client&lt;/h2&gt;
&lt;p&gt;Now we are ready for some coding. We&amp;#8217;ll create a Kafka Producer and Consumer using the standard confluent-kafka library and connect it to a Hopsworks cluster. You can find the source code for all examples at &lt;a class="reference external" href="https://github.com/alshishtawy/hopsworks-examples/tree/main/kafka"&gt;Kafka Hopsworks Examples at GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will need a working Python environment and the following&amp;nbsp;packages:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install confluent_kafka requests fastavro toml
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For plotting you might need the following packages depending on your&amp;nbsp;environment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install matplotlib
pip install pyqt5
sudo apt install qt5-default
&lt;/pre&gt;&lt;/div&gt;
&lt;!-- https://www.confluent.io/blog/avro-kafka-data/ --&gt;
&lt;div class="section" id="configuration-file"&gt;
&lt;h3&gt;Configuration&amp;nbsp;File&lt;/h3&gt;
&lt;p&gt;We&amp;#8217;ll write down all the parameters we prepared in the previous section in a configuration file. This makes it easier to change and also to switch between multiple projects or deployments by switching configuration&amp;nbsp;files.&lt;/p&gt;
&lt;p&gt;Go through the parameters and change them accordingly to match your project settings. Then save it as &lt;a class="reference external" href="https://github.com/alshishtawy/hopsworks-examples/blob/main/kafka/config.toml"&gt;config.toml&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[hops]&lt;/span&gt;
&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# for testing only! set this flag to false or path to server certificate file&lt;/span&gt;
&lt;span class="c1"&gt;# needed when testing Hopsworks with a self signed certificate&lt;/span&gt;
&lt;span class="c1"&gt;# otherwise leave this true&lt;/span&gt;
&lt;span class="n"&gt;verify&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;

&lt;span class="k"&gt;[project]&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;Kafka_Tutorial&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;1143&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;ca_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cert/trustStore.pem&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;certificate_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cert/keyStore.pem&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;key_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cert/keyStore.pem&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;key_password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;asdf123&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;[kafka]&lt;/span&gt;
&lt;span class="n"&gt;topic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;temperature&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;schema&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;sensor&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;9092&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;[kafka.consumer]&lt;/span&gt;
&lt;span class="n"&gt;group_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;TutorialGroup&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;auto_offset_reset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;earliest&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;[api]&lt;/span&gt;
&lt;span class="n"&gt;base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;/hopsworks-api/api&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;K97n09yskcBuuFyO.scfQegUMhXfHg7v3Tpk8t6HIPUlmIP463BPdbTSdSEKAfo5AB8SIwY8LGgB4924B&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;key_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;cert/apiKeyFile&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="sensor-data"&gt;
&lt;h3&gt;Sensor&amp;nbsp;Data&lt;/h3&gt;
&lt;p&gt;We&amp;#8217;ll need some data to test our example. For that we&amp;#8217;ll generate a time series with trend, seasonality, and noise. The code can emulate multiple sensors. The generated data looks like the plot&amp;nbsp;below.&lt;/p&gt;
&lt;img alt="Sensor Data Sample" class="align-center" src="https://alshishtawy.github.io/images/kafka/sensor_data_sample.png" style="width: 100%;" /&gt;
&lt;p&gt;The code below for &lt;a class="reference external" href="https://github.com/alshishtawy/hopsworks-examples/blob/main/kafka/sensor.py"&gt;sensor.py&lt;/a&gt; generates the data.
The code was inspired by &lt;a class="reference external" href="https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c01_common_patterns.ipynb"&gt;this example&lt;/a&gt;.
You can test it yourself by executing the&amp;nbsp;file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python sensor.py
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="c1"&gt;# Generates a time series with trend, seasonality, and noise.&lt;/span&gt;
&lt;span class="c1"&gt;# Inspired by code from https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c01_common_patterns.ipynb&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;trend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;seasonal_pattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;season_time&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Just an arbitrary pattern, you can change it if you wish&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;season_time&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;  &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;season_time&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;season_time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;seasonality&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Repeats the same pattern at each period&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;season_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;seasonal_pattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;season_time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;white_noise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normalvariate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;

&lt;span class="c1"&gt;# Combines the above functions to emulate a sensor.&lt;/span&gt;
&lt;span class="c1"&gt;# Uses Python generator function&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;baseline&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;trend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;seasonality&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;white_noise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="c1"&gt;# initialize a number of sensors&lt;/span&gt;
    &lt;span class="n"&gt;sensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# a list of buffers to emulate receving data&lt;/span&gt;
    &lt;span class="n"&gt;data_buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sensors&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;

    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sensors&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([])[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sensors&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data_buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush_events&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;



    &lt;span class="c1"&gt;# pause execution so you can examin the figure&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Press Enter to continue...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="avro-producer"&gt;
&lt;h3&gt;Avro&amp;nbsp;Producer&lt;/h3&gt;
&lt;p&gt;With all preparation work out of the way, we are now ready to securely send sensor events into our HopsWorks Kafka topic. Below is the code for the &lt;a class="reference external" href="https://github.com/alshishtawy/hopsworks-examples/blob/main/kafka/avro_producer.py"&gt;avro_producer.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code starts by defining an &lt;strong&gt;&amp;#8220;Event&amp;#8220;&lt;/strong&gt; class. This is the class for the objects we want to push into Kafka. You can change this class to match your application. The &lt;strong&gt;&amp;#8220;event_to_dict&amp;#8220;&lt;/strong&gt; is a helper function that returns a dictionary representation of an event object to be used by the Avro serializer. Note that the key names should match the field names defined in the schema and also the value types should match those in the&amp;nbsp;schema.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;&amp;#8220;main()&amp;#8220;&lt;/strong&gt; function loads the configuration file and initializes the schema registry client, Avro serializer, and the producer.
Then initializes a number of sensors to generate data and finally uses the producer to push the generated data into&amp;nbsp;Kafka.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="c1"&gt;# This is a simple example of the SerializingProducer using Avro.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SerializingProducer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.serialization&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StringSerializer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SchemaRegistryClient&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry.avro&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AvroSerializer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;record_subject_name_strategy&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;toml&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sensor&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sensor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;
    An object representing a sensor event

    Args:
        id (str): Sensor's id

        timestamp (datetime): timestamp in milliseconds

        value (double): Sensor's reading value

    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timestamp&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;event_to_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;
    Returns a dict representation of a sensor Event instance for serialization.

    Args:
        event (Event): Event instance.

        ctx (SerializationContext): Metadata pertaining to the serialization
            operation.

    Returns:
        dict: Dict populated with sensor event attributes to be serialized.

    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;delivery_report&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;
    Reports the failure or success of a message delivery.

    Args:
        err (KafkaError): The error that occurred on None on success.

        msg (Message): The message that was produced or failed.

    Note:
        In the delivery report callback the Message.key() and Message.value()
        will be the binary format as encoded by any configured Serializers and
        not the same object that was passed to produce().
        If you wish to pass the original object(s) for key and value to delivery
        report callback we recommend a bound callback or lambda where you pass
        the objects along.

    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Delivery failed for sensor Event &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Sensor Event &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; successfully produced to &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; [&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;] at offset &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;topic&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Parse arguments&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Produces time series data from emulated '&lt;/span&gt;
                                     &lt;span class="s1"&gt;'sensors into a kafka topic hosted at a HopsWorks cluster.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-c&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--config&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'config.toml'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Configuration file in toml format.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-t&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Start time step for the time series generator. Used to resume '&lt;/span&gt;
                        &lt;span class="s1"&gt;'generating the time series after stopping the program.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-e&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--events&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Number of events to generate per sensor. Negative for infinite number.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-d&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--delay&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Delay between events in second. Can be float.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# Load HopsWorks Kafka configuration&lt;/span&gt;
    &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;toml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Kafka schema that this program supports/expects&lt;/span&gt;
    &lt;span class="c1"&gt;# The schema will be checked against the schema of the Kafka topic&lt;/span&gt;
    &lt;span class="n"&gt;schema_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;
    {
      &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;sensor&amp;quot;,
      &amp;quot;fields&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;timestamp&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;,
          &amp;quot;logicalType&amp;quot;: &amp;quot;timestamp-millis&amp;quot;
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;value&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;
        }
      ]
    }
    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="c1"&gt;# url for the schema registry in HopsWorks REST API services&lt;/span&gt;
    &lt;span class="n"&gt;registry_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://'&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;\
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'api'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'base'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'/project/'&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;'/kafka'&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialise the Confluent schema registry client&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;registry_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ssl.ca.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'verify'&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SchemaRegistryClient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schema_registry_conf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Add the API key required by HopsWorks but not configurable through the confluent schema registry client&lt;/span&gt;
    &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'Authorization'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'ApiKey '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'api'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key'&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_rest_client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize the avro serializer for the value using the schema&lt;/span&gt;
    &lt;span class="n"&gt;avro_serializer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AvroSerializer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schema_registry_client&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;schema_str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;event_to_dict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'auto.register.schemas'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'subject.name.strategy'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;record_subject_name_strategy&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize a simple String serializer for the key&lt;/span&gt;
    &lt;span class="n"&gt;string_serializer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StringSerializer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'utf_8'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize the producer&lt;/span&gt;
    &lt;span class="n"&gt;producer_conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'bootstrap.servers'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'port'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'security.protocol'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'SSL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.ca.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'ca_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.certificate.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'certificate_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.key.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.key.password'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key_password'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'key.serializer'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;string_serializer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="s1"&gt;'value.serializer'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avro_serializer&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;producer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SerializingProducer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;producer_conf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize a number of sensors&lt;/span&gt;
    &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;
    &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;events&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;events&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;sensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;sensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;   &lt;span class="n"&gt;period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# Start producing events&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Producing sensor events to topic &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;.&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'topic'&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Press Ctrl-c to exit.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time_step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;     &lt;span class="c1"&gt;# a counter for the number of time steps generated&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sensors&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;timestamp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;time_step&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="c1"&gt;# Serve on_delivery callbacks from previous calls to produce()&lt;/span&gt;
                &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;poll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'sensor'&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                  &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;produce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'topic'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;on_delivery&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;delivery_report&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;break&lt;/span&gt;
                &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Invalid input, discarding record...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="k"&gt;continue&lt;/span&gt;
            &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;Stopping...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Flushing records...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'To continue execution start from event &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time_step&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The program takes a number of optional command line arguments to control the execution. You can specify the location of the configuration file using the -c flag. You can use -e to control the number of events generated per sensor and -d for the delay between events per sensor. The -t flag is used to resume the generation of the time series from the specified time step. This is useful if you want to continue generating more events after the program finishes or&amp;nbsp;stopped.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python avro_producer.py --help
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ python avro_producer.py --help
usage: avro_producer.py [-h] [-c CONFIG] [-t TIME] [-e EVENTS] [-d DELAY]

Produces time series data from emulated sensors into a kafka topic hosted at a HopsWorks cluster.

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        Configuration file in toml format.
  -t TIME, --time TIME  Start time step for the time series generator. Used to resume generating
                        the time series after stopping the program.
  -e EVENTS, --events EVENTS
                        Number of events to generate per sensor. Negative for infinite number.
  -d DELAY, --delay DELAY
                        Delay between events in second. Can be float.
&lt;/pre&gt;
&lt;div class="admonition warning"&gt;
&lt;p class="first admonition-title"&gt;Warning&lt;/p&gt;
&lt;p&gt;There is a bug in the HopsWorks &lt;span class="caps"&gt;REST&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; implementation for the schema registry that causes an &lt;span class="caps"&gt;HTTP&lt;/span&gt; error code 415
&amp;#8220;Unsupported Media&amp;nbsp;Type&amp;#8221;.&lt;/p&gt;
&lt;p&gt;The reason for this error is a mismatch of the content type sent between the client and the server.
The Confluent schema registry client is sending the correct type which is &lt;strong&gt;&amp;#8216;application/vnd.schemaregistry.v1+json&amp;#8217;&lt;/strong&gt;.
While the Hopsworks &lt;span class="caps"&gt;REST&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; server is expecting content of type &lt;strong&gt;&amp;#8216;application/json&amp;#8217;&lt;/strong&gt;.
The bug is reported to the HopsWorks team and is expected to be fixed in upcoming releases after&amp;nbsp;v2.2.&lt;/p&gt;
&lt;p&gt;The easiest workaround is to change the Confluent schema registry client to send content type &amp;#8216;application/json&amp;#8217;.
This should be &lt;span class="caps"&gt;OK&lt;/span&gt; if you are using Python virtualenv as this change will not affect other&amp;nbsp;applications.&lt;/p&gt;
&lt;p&gt;Edit the file &lt;a class="reference external" href="https://github.com/confluentinc/confluent-kafka-python/blob/97f08fe107d259eff6f9c281a61d92e204d2935d/src/confluent_kafka/schema_registry/schema_registry_client.py#L165"&gt;schema_registry_client.py&lt;/a&gt;
in your local python install directory and search for the line with &lt;em&gt;&amp;#8216;Content-Type&amp;#8217;&lt;/em&gt; (line 165 in confluent-kafka v1.7.0)
and change it to:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;'Content-Type':&lt;/span&gt; &amp;quot;application/json&amp;quot;}&lt;/tt&gt;&lt;/p&gt;
&lt;p class="last"&gt;The location of the file depends on your Python installation. If you are using virtualenv it will look something like:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;~/.virtualenvs/myvenv/lib/python3.8/site-packages/confluent_kafka/schema_registry/schema_registry_client.py&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now lets generate some events. Below is a sample execution of 5 events with 0.5 seconds&amp;nbsp;delay:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python avro_producer.py -e &lt;span class="m"&gt;5&lt;/span&gt; -d &lt;span class="m"&gt;0&lt;/span&gt;.5
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ python avro_producer.py -e 5 -d 0.5
Producing sensor events to topic temperature.
Press Ctrl-c to exit.
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 0
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 1
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 2
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 3
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 4
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 5
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 6
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 7
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 0
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 1
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 2
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 3
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 4
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 5
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 6
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 7
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 8
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 9
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 10
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 11
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 8
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 9
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 10
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 11
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 12
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 13
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 14
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 15
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 12
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 13
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 14
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 15
Flushing records...
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 16
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 17
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 18
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 19
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 16
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 17
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 18
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 19
To continue execution start from event 5
&lt;/pre&gt;
&lt;p&gt;Let&amp;#8217;s generate some more events. Notice the last line in the execution above. It prints the time step that should be used to continue execution. To do that, we add &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-t&lt;/span&gt; 5&lt;/tt&gt; to the&amp;nbsp;command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python avro_producer.py -e &lt;span class="m"&gt;5&lt;/span&gt; -d &lt;span class="m"&gt;0&lt;/span&gt;.5 -t &lt;span class="m"&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ python avro_producer.py -e 5 -d 0.5 -t 5
Producing sensor events to topic temperature.
Press Ctrl-c to exit.
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 20
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 21
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 22
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 23
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 24
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 25
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 26
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 27
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 20
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 21
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 22
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 23
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 24
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 25
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 26
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 27
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 28
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 29
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 30
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 31
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 28
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 29
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 30
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 31
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 32
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 33
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 34
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 35
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 32
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 33
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 34
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 35
Flushing records...
Sensor Event b'sensor0' successfully produced to temperature [0] at offset 36
Sensor Event b'sensor1' successfully produced to temperature [0] at offset 37
Sensor Event b'sensor2' successfully produced to temperature [0] at offset 38
Sensor Event b'sensor3' successfully produced to temperature [0] at offset 39
Sensor Event b'sensor4' successfully produced to temperature [1] at offset 36
Sensor Event b'sensor5' successfully produced to temperature [1] at offset 37
Sensor Event b'sensor6' successfully produced to temperature [1] at offset 38
Sensor Event b'sensor7' successfully produced to temperature [1] at offset 39
To continue execution start from event 10
&lt;/pre&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p&gt;Remember that when we created the &amp;#8216;temperature&amp;#8217; topic we set the number of partitions to two.
In the output sample the partition number is shown in the square brackets after the topic name. For example &amp;#8216;temperature [0]&amp;#8217;.
This means that the event was successfully sent to the temperature topic at partition&amp;nbsp;0.&lt;/p&gt;
&lt;p class="last"&gt;Notice that events from the same sensor (e.g., sensor5) always ends up in the same partition (partition [1] in case of sensor5).
This is enforced by Kafka to guarantee the ordered processing of events per event source.
This is implemented using the &lt;strong&gt;key&lt;/strong&gt; of the produced event which in our case is the sensor id.
So pay attention to what you choose as the key depending on the&amp;nbsp;application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="avro-consumer"&gt;
&lt;h3&gt;Avro&amp;nbsp;Consumer&lt;/h3&gt;
&lt;p&gt;The Avro consumer code is similar to the producer code in previous section. It starts with the &lt;strong&gt;&amp;#8220;Event&amp;#8220;&lt;/strong&gt; class which is the same
as the one in the producer code. The rest is similar but works in the other direction. So now we have a &lt;strong&gt;&amp;#8220;dict_to_event&amp;#8220;&lt;/strong&gt; helper function that will return an event object and in the &lt;strong&gt;&amp;#8220;main()&amp;#8220;&lt;/strong&gt; function we&amp;#8217;ll initialize an Avro deserializer and a consumer. Finally the code loops to poll messages and plot the&amp;nbsp;values.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="c1"&gt;# This is a simple example of the SerializingProducer using Avro.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DeserializingConsumer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SchemaRegistryClient&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry.avro&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AvroDeserializer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.serialization&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StringDeserializer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;confluent_kafka.schema_registry&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;record_subject_name_strategy&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;toml&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;
    An object representing a sensor event

    Args:
        id (str): Sensor's id

        timestamp (datetime): timestamp in milliseconds

        value (double): Sensor's reading value

    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timestamp&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;dict_to_event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;
    Converts object literal(dict) to an Event instance.

    Args:
        obj (dict): Object literal(dict)

        ctx (SerializationContext): Metadata pertaining to the serialization
            operation.

    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'timestamp'&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'value'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# Parse arguments&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Consumes events from kafka topic hosted at a HopsWorks cluster.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-c&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--config&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'config.toml'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Configuration file in toml format.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--sensors&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'The total number of sensors to visualize.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# Load HopsWorks Kafka configuration&lt;/span&gt;
    &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;toml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Kafka schema that this program supports/expects&lt;/span&gt;
    &lt;span class="c1"&gt;# The schema will be checked against the schema of the Kafka topic&lt;/span&gt;
    &lt;span class="n"&gt;schema_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;
    {
      &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;sensor&amp;quot;,
      &amp;quot;fields&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;timestamp&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;,
          &amp;quot;logicalType&amp;quot;: &amp;quot;timestamp-millis&amp;quot;
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;value&amp;quot;,
          &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;
        }
      ]
    }
    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="c1"&gt;# url for the schema registry in HopsWorks REST API services&lt;/span&gt;
    &lt;span class="n"&gt;registry_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://'&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;\
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'api'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'base'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'/project/'&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;'/kafka'&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialise the Confluent schema registry client&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;registry_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ssl.ca.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'verify'&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SchemaRegistryClient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schema_registry_conf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Add the API key required by HopsWorks but not configurable through the confluent schema registry client&lt;/span&gt;
    &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'Authorization'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'ApiKey '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'api'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key'&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
    &lt;span class="n"&gt;schema_registry_client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_rest_client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize the avro deserializer for the value using the schema&lt;/span&gt;
    &lt;span class="n"&gt;avro_deserializer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AvroDeserializer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schema_registry_client&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                         &lt;span class="n"&gt;schema_str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                         &lt;span class="n"&gt;dict_to_event&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize a simple String deserializer for the key&lt;/span&gt;
    &lt;span class="n"&gt;string_deserializer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StringDeserializer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'utf_8'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Initialize the consumer&lt;/span&gt;
    &lt;span class="n"&gt;consumer_conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'bootstrap.servers'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'hops'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'port'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'security.protocol'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'SSL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.ca.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'ca_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.certificate.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'certificate_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.key.location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key_file'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'ssl.key.password'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'project'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'key_password'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'key.deserializer'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;string_deserializer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="s1"&gt;'value.deserializer'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avro_deserializer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="s1"&gt;'group.id'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'consumer'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'group_id'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="s1"&gt;'auto.offset.reset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'consumer'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'auto_offset_reset'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DeserializingConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;consumer_conf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Subscribe to a topic&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subscribe&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'kafka'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'topic'&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

    &lt;span class="c1"&gt;# a list of buffers to store data for plotting&lt;/span&gt;
    &lt;span class="n"&gt;MAX_BUFFER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt; &lt;span class="c1"&gt;# max events to store for plotting, then graph will scroll&lt;/span&gt;
    &lt;span class="n"&gt;buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_BUFFER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sensors&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="c1"&gt;# Plotting&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([])[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="c1"&gt;# x is shared, so set lim once&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
            &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush_events&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# loop for consuming events&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c1"&gt;# time for replotting every delta seconds&lt;/span&gt;
    &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# plot&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

            &lt;span class="c1"&gt;# SIGINT can't be handled when polling, limit timeout to 1 second.&lt;/span&gt;
            &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;poll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;

            &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Event record &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;: id: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                      &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;timestamp: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                      &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;value: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="c1"&gt;# store event in buffer for plotting&lt;/span&gt;
                &lt;span class="nb"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
                &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

    &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Run &lt;tt class="docutils literal"&gt;avro_consumer.py&lt;/tt&gt; with the command below. It will start receiving and plotting the 10 events we produced in the previous example. After that the program will wait for more events. Keep it running as we&amp;#8217;ll be producing more events&amp;nbsp;soon.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;The consumer received the 10 events we generated in the previous section because we set the &lt;tt class="docutils literal"&gt;auto.offset.reset&lt;/tt&gt; property to &lt;tt class="docutils literal"&gt;'earliest'&lt;/tt&gt; in our configuration file. This causes a consumer group, when first created, to get all available events in the Kafka topic. Another option is &lt;tt class="docutils literal"&gt;'latest'&lt;/tt&gt; which will cause the consumer group to get only the current events ignoring old ones. Read more about consumer groups and offset management &lt;a class="reference external" href="https://docs.confluent.io/platform/current/clients/consumer.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python avro_consumer.py
&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="terminal literal-block"&gt;
$ python avro_consumer.py
Event record sensor4: id: sensor4
        timestamp: 2021-09-16 18:32:45
        value: 73.43209881486389

Event record sensor5: id: sensor5
        timestamp: 2021-09-16 18:32:45
        value: 53.20542290369634

Event record sensor6: id: sensor6
        timestamp: 2021-09-16 18:32:45
        value: -1.6974040527855028

Event record sensor7: id: sensor7
        timestamp: 2021-09-16 18:32:45
        value: 34.33728468834174

Event record sensor4: id: sensor4
        timestamp: 2021-09-16 18:32:46
        value: 73.99429517973576

Event record sensor5: id: sensor5
        timestamp: 2021-09-16 18:32:46
        value: 46.444456025618216
...
&lt;/pre&gt;
&lt;p&gt;Keep the &lt;tt class="docutils literal"&gt;avro_producer.py&lt;/tt&gt; running and try generating 20 more events with the command&amp;nbsp;below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python avro_producer.py -e &lt;span class="m"&gt;20&lt;/span&gt; -d &lt;span class="m"&gt;0&lt;/span&gt;.5 -t &lt;span class="m"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The producer will start producing more events and you will see the consumer receiving and plotting them. The output should be similar to the figure&amp;nbsp;below.&lt;/p&gt;
&lt;img alt="Kafka example with one consumer" class="align-center" src="https://alshishtawy.github.io/images/kafka/kafka_prod_one_cons.png" style="width: 100%;" /&gt;
&lt;p&gt;Now try creating another &lt;tt class="docutils literal"&gt;avro_consumer.py&lt;/tt&gt; in another terminal leaving the previous one&amp;nbsp;running.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python avro_consumer.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then produce 20 more&amp;nbsp;events:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python avro_producer.py -e &lt;span class="m"&gt;20&lt;/span&gt; -d &lt;span class="m"&gt;0&lt;/span&gt;.5 -t &lt;span class="m"&gt;30&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that now the produced events will be split between the two consumers, or to be more precise, the partitions will be split among the available consumers. Since we created two partitions, we can have a maximum of two consumers. The output should look similar to the image&amp;nbsp;below.&lt;/p&gt;
&lt;img alt="Kafka example with two consumers" class="align-center" src="https://alshishtawy.github.io/images/kafka/kafka_prod_two_cons.png" style="width: 100%;" /&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;Kafka remembers the events consumed by a consumer group. So if a consumer is interrupted and then restarted, it will continue from where it stopped. This is achieved through the consumer &lt;strong&gt;commit&lt;/strong&gt; the offsets corresponding to the messages it has read. This can be configured to provide different delivery guarantees. The default is &lt;strong&gt;auto-commit&lt;/strong&gt; that gives you &lt;strong&gt;at least once&lt;/strong&gt; delivery guarantee. You can read more about this topic &lt;a class="reference external" href="https://docs.confluent.io/platform/current/clients/consumer.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="source-code"&gt;
&lt;h2&gt;Source&amp;nbsp;Code&lt;/h2&gt;
&lt;p&gt;All source code is available at &lt;a class="reference external" href="https://github.com/alshishtawy/hopsworks-examples/tree/main/kafka"&gt;Kafka HopsWorks Examples at&amp;nbsp;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;!-- https://pythonhosted.org/sphinxjp.themes.basicstrap/sample.html#admonitions-docutils-origin --&gt;
&lt;/div&gt;
</content><category term="Guides"></category><category term="Kafka"></category><category term="Spark"></category><category term="Hopsworks"></category><category term="Python"></category><category term="Stream Processing"></category></entry><entry><title>Traffic Flow Analysis with Spark: Getting StartedÂ Guide</title><link href="https://alshishtawy.github.io/traffic-flow-analysis.html" rel="alternate"></link><published>2017-10-13T00:00:00+02:00</published><updated>2017-10-13T00:00:00+02:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2017-10-13:/traffic-flow-analysis.html</id><summary type="html">&lt;p class="first last"&gt;A guide that helps you get started with traffic flow analysis using&amp;nbsp;Spark&lt;/p&gt;
</summary><content type="html">&lt;img alt="Traffic Flow Analysis" class="align-center" src="https://alshishtawy.github.io/images/traffic_flow.png" style="width: 90%;" /&gt;
&lt;p&gt;This guide will help you get started with traffic flow analysis of sensor data from Motorway Control Systems (&lt;span class="caps"&gt;MCS&lt;/span&gt;) using&amp;nbsp;Spark.&lt;/p&gt;
&lt;p&gt;To get started, download the Jupyter Notebook and the sample data from the links below. Run the Notebook in Jupyter and follow it step by step as it walks you through the basic stages of data&amp;nbsp;analytics.&lt;/p&gt;
&lt;p&gt;You can view a static version of the notebook here: &lt;a class="reference external" href="https://alshishtawy.github.io/static/Traffic_Flow_Analysis/Traffic_Flow_Analysis_with_Spark.html"&gt;Traffic Flow Analysis (Static&amp;nbsp;Version)&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="setting-up-a-working-environment"&gt;
&lt;h2&gt;Setting Up a Working&amp;nbsp;Environment&lt;/h2&gt;
&lt;p&gt;If you don&amp;#8217;t have access to a Spark and/or Jupyter installation. You can quickly get it up and running using Docker. We recommend using this &lt;a class="reference external" href="https://github.com/jupyter/docker-stacks/tree/master/all-spark-notebook"&gt;Spark Docker image&lt;/a&gt; that contains all the tools we need. Including, Spark, Jupyter, Python, Scala, and much&amp;nbsp;more.&lt;/p&gt;
&lt;p&gt;Follow these&amp;nbsp;steps:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Install&amp;nbsp;Docker&lt;/li&gt;
&lt;li&gt;Create a folder (e.g., /home/myuser/work) and copy the Notebook and unzipped sample data folder&amp;nbsp;there&lt;/li&gt;
&lt;li&gt;Run docker with the following command (&lt;strong&gt;replace&lt;/strong&gt;  /home/myuser/work with your&amp;nbsp;folder)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run -it --rm -p &lt;span class="m"&gt;8888&lt;/span&gt;:8888 --name mySpark -v /home/myuser/work:/home/jovyan/work jupyter/all-spark-notebook
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should start Spark and Jupyter. Take note of the authentication token included in the Jupyter startup log messages. Use this url in your browser to access&amp;nbsp;Jupyter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="resources"&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://alshishtawy.github.io/static/Traffic_Flow_Analysis/Traffic_Flow_Analysis_with_Spark.ipynb"&gt;Traffic Flow Analysis Jupyter&amp;nbsp;Notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://alshishtawy.github.io/static/Traffic_Flow_Analysis/data.zip"&gt;Sample&amp;nbsp;Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Guides"></category><category term="Spark"></category><category term="Big Data"></category><category term="Traffic Flow"></category><category term="Analytics"></category><category term="Jupyter"></category></entry><entry><title>HDFS Contents Manager for JupyterÂ Notebooks</title><link href="https://alshishtawy.github.io/hdfs-contents-manager.html" rel="alternate"></link><published>2017-08-07T11:00:00+02:00</published><updated>2017-08-07T11:00:00+02:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2017-08-07:/hdfs-contents-manager.html</id><summary type="html">&lt;p&gt;I implemented a contents manager for &lt;a class="reference external" href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; notebooks that uses &lt;span class="caps"&gt;HDFS&lt;/span&gt; as a storage backend to store notebooks.
I have two versions. The main difference is the library used to read/write &lt;span class="caps"&gt;HDFS&lt;/span&gt;.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The first version uses &lt;a class="reference external" href="https://github.com/dask/hdfs3"&gt;&lt;span class="caps"&gt;HDFS3&lt;/span&gt;&lt;/a&gt; which is based on libhdfs3, a native C/C++ library to interact â¦&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;I implemented a contents manager for &lt;a class="reference external" href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; notebooks that uses &lt;span class="caps"&gt;HDFS&lt;/span&gt; as a storage backend to store notebooks.
I have two versions. The main difference is the library used to read/write &lt;span class="caps"&gt;HDFS&lt;/span&gt;.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The first version uses &lt;a class="reference external" href="https://github.com/dask/hdfs3"&gt;&lt;span class="caps"&gt;HDFS3&lt;/span&gt;&lt;/a&gt; which is based on libhdfs3, a native C/C++ library to interact with the Hadoop
File System (&lt;span class="caps"&gt;HDFS&lt;/span&gt;).&lt;/li&gt;
&lt;li&gt;The second version uses &lt;a class="reference external" href="http://crs4.github.io/pydoop/"&gt;Pydoop&lt;/a&gt; which is based on the official &lt;a class="reference external" href="https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/LibHdfs.html"&gt;libhdfs&lt;/a&gt;, a &lt;span class="caps"&gt;JNI&lt;/span&gt; based C &lt;span class="caps"&gt;API&lt;/span&gt; for Hadoop&amp;#8217;s Distributed
File System (&lt;span class="caps"&gt;HDFS&lt;/span&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class="caps"&gt;HDFS&lt;/span&gt; Contents Manager is used to add &lt;a class="reference external" href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; support to the &lt;a class="reference external" href="http://www.hops.io/"&gt;Hops&lt;/a&gt; Big Data platform. Check out the &lt;a class="reference external" href="https://alshishtawy.github.io/pdfs/posters/2017/HopsJupyter_V2.pdf"&gt;&lt;span class="caps"&gt;HDFS&lt;/span&gt; Contents
Manager poster&lt;/a&gt; at the &lt;span class="caps"&gt;SICS&lt;/span&gt; Open House 2017 event for more&amp;nbsp;details.&lt;/p&gt;
&lt;div class="section" id="source-code"&gt;
&lt;h2&gt;Source&amp;nbsp;Code&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The &lt;a class="reference external" href="https://github.com/alshishtawy/hdfscontents"&gt;&lt;span class="caps"&gt;HDFS3&lt;/span&gt;&amp;nbsp;version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The &lt;a class="reference external" href="https://github.com/hopshadoop/hdfscontents"&gt;pydoop&amp;nbsp;version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Projects"></category><category term="Big Data"></category><category term="Open Source"></category><category term="Jupyter"></category><category term="HDFS"></category></entry><entry><title>OnlineElastMan: Self-Trained Proactive Elasticity Manager for Cloud-Based StorageÂ Services</title><link href="https://alshishtawy.github.io/online-elastman.html" rel="alternate"></link><published>2016-03-18T00:00:00+01:00</published><updated>2017-04-11T00:00:00+02:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2016-03-18:/online-elastman.html</id><summary type="html">&lt;p class="first last"&gt;A self-trained procative elasticity manager for the&amp;nbsp;Cloud&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The pay-as-you-go pricing model and the illusion of unlimited resources in the Cloud initiate the idea to provision
services elastically. Elastic provisioning of services allocates/de-allocates resources dynamically in response to the
changes of the workload. It minimizes the service provisioning cost while maintaining the desired service level
objectives (SLOs). Model-predictive control is often used in building such elasticity controllers that dynamically
provision resources. However, they need to be trained, either online or offline, before making accurate scaling
decisions. The training process involves tedious and significant amount of work as well as some expertise, especially
when the model has many dimensions and the training granularity is fine, which is proved to be essential in order to
build an accurate elasticity&amp;nbsp;controller.&lt;/p&gt;
&lt;p&gt;OnlineElastMan is a self-trained proactive elasticity manager for cloud-based storage services. It automatically evolves
itself while serving the workload. Experiments using OnlineElastMan with Cassandra indicate that OnlineElastMan
continuously improves its provision accuracy, i.e., minimizing provisioning cost and &lt;span class="caps"&gt;SLO&lt;/span&gt; violations, under various
workload&amp;nbsp;patterns.&lt;/p&gt;
&lt;div class="section" id="publications"&gt;
&lt;h2&gt;Publications&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Y. Liu, D. Gureya, A. Al-Shishtawy, and V. Vlassov, &lt;strong&gt;&amp;#8220;OnlineElastMan: Self-Trained Proactive Elasticity Manager for
Cloud-Based Storage Services, &amp;#8220;&lt;/strong&gt; in Cluster Computing, &lt;span class="caps"&gt;ISSN&lt;/span&gt; 1573-7543, May 2017. &lt;a class="reference external image-reference" href="https://doi.org/10.1007/s10586-017-0899-z"&gt;&lt;img alt="10.1007/s10586-017-0899-z" src="https://alshishtawy.github.io/images/doi.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/CC2017_OnlineElastMan.pdf"&gt;&lt;img alt="pdf" src="https://alshishtawy.github.io/images/pdf.png" style="height: 1em;" /&gt;&lt;/a&gt;
&lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/CC2017_OnlineElastMan.bib"&gt;&lt;img alt="bibtex" src="https://alshishtawy.github.io/images/bibtex.png" style="height: 1em;" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Y. Liu, D. Gureya, A. Al-Shishtawy and V. Vlassov, &lt;strong&gt;&amp;#8220;OnlineElastMan: Self-Trained Proactive Elasticity Manager for
Cloud-Based Storage Services,&amp;#8221;&lt;/strong&gt; &lt;span class="caps"&gt;IEEE&lt;/span&gt; International Conference on Cloud and Autonomic Computing (&lt;span class="caps"&gt;ICCAC&lt;/span&gt;), Augsburg,
2016, pp. 50-59. &lt;a class="reference external image-reference" href="http://dx.doi.org/10.1109/ICCAC.2016.11"&gt;&lt;img alt="10.1109/ICCAC.2016.11" src="https://alshishtawy.github.io/images/doi.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/ICCAC2016_OnlineElastMan.pdf"&gt;&lt;img alt="pdf" src="https://alshishtawy.github.io/images/pdf.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/ICCAC2016_OnlineElastMan.bib"&gt;&lt;img alt="bibtex" src="https://alshishtawy.github.io/images/bibtex.png" style="height: 1em;" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="source-code"&gt;
&lt;h2&gt;Source&amp;nbsp;Code&lt;/h2&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/gureya/OnlineElasticityManager"&gt;OnlineElastMan&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="Projects"></category><category term="Elasticity"></category><category term="Open Source"></category><category term="Cloud Computing"></category></entry><entry><title>SpanEdge: Towards Unifying Stream Processing over Central and Near-the-Edge DataÂ Centers</title><link href="https://alshishtawy.github.io/spanedge.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><updated>2016-12-08T00:00:00+01:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2015-12-01:/spanedge.html</id><summary type="html">&lt;p class="first last"&gt;Unifying Stream Processing over Central and Near-the-Edge Data&amp;nbsp;Centers&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Distributed Stream Processing Systems are typically deployed within a single data center in order to achieve high
performance and low-latency computation. The data streams analyzed by such systems are expected to be available in the
same data center. Either the data streams are generated within the data center (e.g., logs, transactions, user clicks)
or they are aggregated by external systems from various sources and buffered into the data center for processing
(e.g., IoT, sensor data, traffic&amp;nbsp;information).&lt;/p&gt;
&lt;p&gt;The data center approach for stream processing analytics fits the requirements of the majority of the applications that
exists today. However, for latency sensitive applications, such as real-time decision-making, which relies on analyzing
geographically distributed data streams, a data center approach might not be sufficient. Aggregating data streams incurs
high overheads in terms of latency and bandwidth consumption in addition to the overhead of sending the analysis
outcomes back to where an action needs to be&amp;nbsp;taken.&lt;/p&gt;
&lt;p&gt;We propose a new stream processing architecture for efficiently analyzing geographically distributed data streams. Our
approach utilizes emerging distributed virtualized environments, such as Mobile Edge Clouds, to extend stream processing
systems outside the data center in order to push critical parts of the analysis closer to the data sources. This will
enable real-time applications to respond faster to geographically distributed&amp;nbsp;events.&lt;/p&gt;
&lt;p&gt;In order to realize our approach, we have implemented a geo-aware scheduler plugin for the Apache Storm stream
processing system. The scheduler takes as an input a Storm topology (Figure 1) to be scheduled and executed on the
available datacenter/edge Cloud resources. The scheduler enables the developers of the topology to annotate groups
of stream processing elements that can be replicated and pushed outside of the data center to an Edge Cloud with
close proximity to the stream source. In order to operate, the scheduler requires knowledge of the available
datacenter/edge Clouds, data stream types available at each Cloud, and latencies among&amp;nbsp;clouds.&lt;/p&gt;
&lt;img alt="ElastMan logo" class="align-center" src="https://alshishtawy.github.io/images/SpanEdge.png" style="width: 90%;" /&gt;
&lt;div class="section" id="publications"&gt;
&lt;h2&gt;Publications&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="caps"&gt;H. P.&lt;/span&gt; Sajjad, K. Danniswara, A. Al-Shishtawy and V. Vlassov, &lt;strong&gt;&amp;#8220;SpanEdge: Towards Unifying Stream Processing over
Central and Near-the-Edge Data Centers,&amp;#8221;&lt;/strong&gt; 2016 &lt;span class="caps"&gt;IEEE&lt;/span&gt;/&lt;span class="caps"&gt;ACM&lt;/span&gt; Symposium on Edge Computing (&lt;span class="caps"&gt;SEC&lt;/span&gt;), Washington, &lt;span class="caps"&gt;DC&lt;/span&gt;, 2016,
pp. 168-178. &lt;a class="reference external image-reference" href="http://dx.doi.org/10.1109/SEC.2016.17"&gt;&lt;img alt="10.1109/SEC.2016.17" src="https://alshishtawy.github.io/images/doi.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/SEC2016_SpanEdge.pdf"&gt;&lt;img alt="pdf" src="https://alshishtawy.github.io/images/pdf.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/SEC2016_SpanEdge_Slides.pdf"&gt;&lt;img alt="slides" src="https://alshishtawy.github.io/images/slides.png" style="height: 1em;" /&gt;&lt;/a&gt; &lt;a class="reference external image-reference" href="https://alshishtawy.github.io/pdfs/publications/SEC2016_SpanEdge.bib"&gt;&lt;img alt="bibtex" src="https://alshishtawy.github.io/images/bibtex.png" style="height: 1em;" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="source-code"&gt;
&lt;h2&gt;Source&amp;nbsp;Code&lt;/h2&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/Telolets/StormOnEdge"&gt;SpanEdge&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="Projects"></category><category term="Edge Computing"></category><category term="Open Source"></category><category term="Cloud Computing"></category></entry><entry><title>ElastMan: Elasticity Manager for Elastic Cloud-BasedÂ Services</title><link href="https://alshishtawy.github.io/elastman.html" rel="alternate"></link><published>2013-09-09T10:00:00+02:00</published><updated>2015-03-16T10:00:00+01:00</updated><author><name>Ahmad Al-Shishtawy</name></author><id>tag:alshishtawy.github.io,2013-09-09:/elastman.html</id><summary type="html">&lt;p class="first last"&gt;Elasticity Manager for Elastic Cloud-Based&amp;nbsp;Services&lt;/p&gt;
</summary><content type="html">&lt;img alt="ElastMan logo" class="align-left" src="https://alshishtawy.github.io/images/ElastManLogo.png" style="width: 25%;" /&gt;
&lt;p&gt;The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has
led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to
changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance
of Cloud Virtual Machines and nonlinearities in Cloud services, such as the diminishing reward of adding a service
instance with increasing the scale, complicates the controller&amp;nbsp;design.&lt;/p&gt;
&lt;p&gt;ElastMan is an elasticity controller for Elastic Cloud-based services. ElastMan combines feedforward and feedback
control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs
at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. To address
nonlinearities, our design of ElastMan leverages the near-linear scalability of elastic Cloud services in order to
build a scale-independent model of the&amp;nbsp;service.&lt;/p&gt;
&lt;p&gt;We have evaluated ElastMan using the Voldemort key-value store running in an OpenStack Cloud environment. Our
evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service&amp;nbsp;elasticity.&lt;/p&gt;
&lt;div class="section" id="publications"&gt;
&lt;h2&gt;Publications&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ElastMan: Elasticity Manager for Elastic Key-Value Stores in the Cloud, Ahmad Al-Shishtawy, Vladimir Vlassov.
The &lt;span class="caps"&gt;ACM&lt;/span&gt; Cloud and Autonomic Computing Conference (&lt;span class="caps"&gt;CAC&lt;/span&gt; 2013), Miami, &lt;span class="caps"&gt;FL&lt;/span&gt;, &lt;span class="caps"&gt;USA&lt;/span&gt;,  August 5-9, 2013. &lt;a class="reference external image-reference" href="http://dx.doi.org/10.1145/2494621.2494630"&gt;&lt;img alt="10.1145/2494621.2494630" src="https://alshishtawy.github.io/images/doi.png" style="height: 14pt;" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ElastMan: Autonomic Elasticity Manager for Cloud-Based Key-value Stores, Ahmad Al-Shishtawy, Vladimir Vlassov. The
22nd &lt;span class="caps"&gt;ACM&lt;/span&gt; International Symposium on High-Performance Parallel and Distributed Computing (&lt;span class="caps"&gt;HPDC&lt;/span&gt; &amp;#8216;13). &lt;span class="caps"&gt;ACM&lt;/span&gt;, New York,
&lt;span class="caps"&gt;NY&lt;/span&gt;, &lt;span class="caps"&gt;USA&lt;/span&gt;, pp. 115-116. &lt;a class="reference external image-reference" href="http://doi.acm.org/10.1145/2462902.2462925"&gt;&lt;img alt="10.1145/2462902.2462925" src="https://alshishtawy.github.io/images/doi.png" style="height: 14pt;" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="source-code"&gt;
&lt;h2&gt;Source&amp;nbsp;Code&lt;/h2&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/alshishtawy/ElastMan"&gt;ElastMan&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="Projects"></category><category term="Elasticity"></category><category term="Open Source"></category><category term="Cloud Computing"></category></entry></feed>